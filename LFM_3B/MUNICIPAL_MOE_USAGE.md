# Municipal MoE Model - Nutzungsanleitung

## ğŸ›ï¸ Ãœbersicht
Das Municipal MoE (Mixture of Experts) Modell ist speziell fÃ¼r deutsche Kommunalverwaltungen entwickelt und verfÃ¼gt Ã¼ber 8 spezialisierte Experten fÃ¼r verschiedene Ã„mter.

## ğŸš€ Erste Schritte

### 1. Basis-Modell erstellen (falls noch nicht vorhanden)
```bash
cd /notebooks/LFM-Liquid-AI-Liquid-Foundation-Models/LFM_3B
python3 municipal_moe_model.py
```
Dies erstellt das Basis-Modell unter `./municipal_moe_base/`

### 2. Modell mit Tokenizer testen
```bash
python3 municipal_tokenizer_integration.py --model-path ./municipal_moe_base --prompt "Ich mÃ¶chte meinen Personalausweis verlÃ¤ngern"
```

### 3. Municipal Demo ausfÃ¼hren
```bash
python3 municipal_tokenizer_integration.py --model-path ./municipal_moe_base --municipal-demo
```

Die Demo zeigt Beispiele fÃ¼r:
- ğŸ“‹ **Einwohnermeldeamt**: Wohnsitz ummelden
- ğŸ—ï¸ **Bauamt**: Baugenehmigung beantragen  
- ğŸ“„ **Standesamt**: Urkunden beantragen
- ğŸš¨ **Ordnungsamt**: Beschwerden melden

### 4. Interaktiver Chat
```bash
python3 municipal_tokenizer_integration.py --model-path ./municipal_moe_base --chat
```

Im Chat-Modus kÃ¶nnen Sie:
- Fragen zu kommunalen Dienstleistungen stellen
- Informationen Ã¼ber BehÃ¶rdengÃ¤nge erhalten
- AntrÃ¤ge und Verfahren erklÃ¤rt bekommen
- Mit 'exit' beenden

### 5. Expert-Routing analysieren
```bash
python3 municipal_tokenizer_integration.py --model-path ./municipal_moe_base --analyze-routing "LÃ¤rmbelÃ¤stigung melden"
```

Zeigt, welche Experten fÃ¼r eine bestimmte Anfrage aktiviert werden.

## ğŸ¢ VerfÃ¼gbare Experten

| Expert ID | ZustÃ¤ndigkeit | Beispielthemen |
|-----------|---------------|----------------|
| 0 | Einwohnermeldeamt | An-/Ummeldung, MeldebestÃ¤tigung |
| 1 | Bauamt | Baugenehmigungen, Bauanzeigen |
| 2 | Ordnungsamt | Ordnungswidrigkeiten, Genehmigungen |
| 3 | Stadtkasse | GebÃ¼hren, Steuern, Zahlungen |
| 4 | Sozialamt | Sozialleistungen, UnterstÃ¼tzung |
| 5 | Standesamt | Geburts-/Sterbeurkunden, EheschlieÃŸung |
| 6 | Jugendamt | Familienleistungen, Kinderbetreuung |
| 7 | General | Allgemeine Verwaltungsfragen |

## ğŸ“ Weitere Optionen

### Parameter fÃ¼r Textgenerierung
- `--max-length`: Maximale LÃ¤nge der generierten Antwort (Standard: 100)
- `--temperature`: KreativitÃ¤t der Antworten (0.1-1.0, Standard: 0.8)

### Beispiele
```bash
# Kurze, prÃ¤zise Antworten
python3 municipal_tokenizer_integration.py --model-path ./municipal_moe_base \
  --prompt "Ã–ffnungszeiten BÃ¼rgeramt" --max-length 50 --temperature 0.3

# AusfÃ¼hrliche ErklÃ¤rungen
python3 municipal_tokenizer_integration.py --model-path ./municipal_moe_base \
  --prompt "Wie beantrage ich einen Reisepass?" --max-length 200 --temperature 0.7
```

## ğŸ”§ Training mit deutschen Verwaltungsdaten

Das Basis-Modell muss erst mit deutschen Texten trainiert werden:

### 1. Trainingsdaten erstellen
```bash
python3 train_municipal_moe.py --create-data
```
Erstellt `municipal_training_data.jsonl` mit ~75 deutschen Verwaltungsbeispielen.

### 2. Modell trainieren
```bash
python3 train_municipal_moe.py --model-path ./municipal_moe_base \
  --data-file municipal_training_data.jsonl \
  --output-dir ./municipal_moe_trained \
  --epochs 3 --batch-size 4
```

### 3. Trainiertes Modell verwenden
```bash
# Nach dem Training das trainierte Modell nutzen:
python3 municipal_tokenizer_integration.py --model-path ./municipal_moe_trained --chat
```

### Training-Parameter
- `--epochs`: Anzahl TrainingsdurchlÃ¤ufe (Standard: 3)
- `--batch-size`: Batch-GrÃ¶ÃŸe (Standard: 4, bei wenig GPU-Speicher reduzieren)
- `--learning-rate`: Lernrate (Standard: 5e-5)
- `--max-length`: Maximale TextlÃ¤nge (Standard: 256)

## ğŸ“Š Modell-Details
- **Basis**: GPT-2 Tokenizer
- **Architektur**: 6 Transformer-Layer mit MoE
- **Experten**: 8 spezialisierte Netzwerke
- **Aktivierung**: Top-2 Experten pro Token
- **Parameter**: ~47M gesamt